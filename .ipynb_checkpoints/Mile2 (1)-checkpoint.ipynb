{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILESTONE 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7f94d6796c6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_rows'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Desktop/459FinalProject/train.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 592\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    593\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[1;34m(self, json)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"frame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"series\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36mparse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    847\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 849\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    851\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\json\\_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1091\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[1;32m-> 1093\u001b[1;33m                 \u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m             )\n\u001b[0;32m   1095\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"split\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import nltk as nltk\n",
    "import cv2\n",
    "import imageio\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.draw.dispersion import dispersion_plot\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#                         category=DeprecationWarning)\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_json('C:/Users/Desktop/459FinalProject/train.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification without outlier removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DECISION TREE CODE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outlier removal:  0.695\n"
     ]
    }
   ],
   "source": [
    "new_df = df.drop(['description', 'building_id', 'manager_id', 'created', 'display_address', 'listing_id', 'street_address', 'photos'], axis=1)\n",
    "df0 = new_df.drop(['features','interest_level'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df0, new_df['interest_level'], test_size=0.40, random_state=0)\n",
    " \n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    " \n",
    "print(\"Before outlier removal: \", clf.score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outlier removal:  0.695\n"
     ]
    }
   ],
   "source": [
    "new_df = df.drop(['description', 'building_id', 'manager_id', 'created', 'display_address', 'listing_id', 'street_address', 'photos'], axis=1)\n",
    "df0 = new_df.drop(['features','interest_level'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df0, new_df['interest_level'], test_size=0.40, random_state=0)\n",
    " \n",
    "clf = SVC(gamma=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Before outlier removal: \", clf.score(X_test, y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier removal \n",
    "\n",
    "### 1. price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9406.000000</td>\n",
       "      <td>9406.000000</td>\n",
       "      <td>9406.000000</td>\n",
       "      <td>9.406000e+03</td>\n",
       "      <td>9406.000000</td>\n",
       "      <td>9406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.139592</td>\n",
       "      <td>1.476079</td>\n",
       "      <td>40.752043</td>\n",
       "      <td>7.161341e+06</td>\n",
       "      <td>-73.971537</td>\n",
       "      <td>3277.191686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.372602</td>\n",
       "      <td>1.059230</td>\n",
       "      <td>0.067396</td>\n",
       "      <td>5.027280e+04</td>\n",
       "      <td>0.052609</td>\n",
       "      <td>1118.313992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.575800</td>\n",
       "      <td>7.087701e+06</td>\n",
       "      <td>-76.633600</td>\n",
       "      <td>700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.727300</td>\n",
       "      <td>7.121902e+06</td>\n",
       "      <td>-73.991600</td>\n",
       "      <td>2495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.751700</td>\n",
       "      <td>7.159148e+06</td>\n",
       "      <td>-73.977200</td>\n",
       "      <td>3059.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.774600</td>\n",
       "      <td>7.197453e+06</td>\n",
       "      <td>-73.953900</td>\n",
       "      <td>3895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>44.603800</td>\n",
       "      <td>7.731327e+06</td>\n",
       "      <td>-71.079400</td>\n",
       "      <td>6540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms     bedrooms     latitude    listing_id    longitude  \\\n",
       "count  9406.000000  9406.000000  9406.000000  9.406000e+03  9406.000000   \n",
       "mean      1.139592     1.476079    40.752043  7.161341e+06   -73.971537   \n",
       "std       0.372602     1.059230     0.067396  5.027280e+04     0.052609   \n",
       "min       0.000000     0.000000    40.575800  7.087701e+06   -76.633600   \n",
       "25%       1.000000     1.000000    40.727300  7.121902e+06   -73.991600   \n",
       "50%       1.000000     1.000000    40.751700  7.159148e+06   -73.977200   \n",
       "75%       1.000000     2.000000    40.774600  7.197453e+06   -73.953900   \n",
       "max       4.000000     8.000000    44.603800  7.731327e+06   -71.079400   \n",
       "\n",
       "             price  \n",
       "count  9406.000000  \n",
       "mean   3277.191686  \n",
       "std    1118.313992  \n",
       "min     700.000000  \n",
       "25%    2495.000000  \n",
       "50%    3059.500000  \n",
       "75%    3895.000000  \n",
       "max    6540.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price = df['price']  \n",
    "IQR = df_price.quantile(0.75)-df_price.quantile(0.25)\n",
    "upper = df_price.quantile(0.75)+IQR*1.5\n",
    "lower = df_price.quantile(0.25)-IQR*1.5 \n",
    "\n",
    "df1 = df[(df['price'] <upper) & (df['price'] >lower)]\n",
    "df1.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Latitude Attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>9086.000000</td>\n",
       "      <td>9086.000000</td>\n",
       "      <td>9086.000000</td>\n",
       "      <td>9.086000e+03</td>\n",
       "      <td>9086.000000</td>\n",
       "      <td>9086.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.140986</td>\n",
       "      <td>1.471164</td>\n",
       "      <td>40.750771</td>\n",
       "      <td>7.161424e+06</td>\n",
       "      <td>-73.972558</td>\n",
       "      <td>3321.198767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.372913</td>\n",
       "      <td>1.061662</td>\n",
       "      <td>0.034619</td>\n",
       "      <td>5.053893e+04</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>1106.764221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.656700</td>\n",
       "      <td>7.087701e+06</td>\n",
       "      <td>-74.045400</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.727825</td>\n",
       "      <td>7.121546e+06</td>\n",
       "      <td>-73.991700</td>\n",
       "      <td>2500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.751600</td>\n",
       "      <td>7.159454e+06</td>\n",
       "      <td>-73.977900</td>\n",
       "      <td>3100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.773500</td>\n",
       "      <td>7.197719e+06</td>\n",
       "      <td>-73.954900</td>\n",
       "      <td>3919.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>40.845500</td>\n",
       "      <td>7.731327e+06</td>\n",
       "      <td>-73.714200</td>\n",
       "      <td>6540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms     bedrooms     latitude    listing_id    longitude  \\\n",
       "count  9086.000000  9086.000000  9086.000000  9.086000e+03  9086.000000   \n",
       "mean      1.140986     1.471164    40.750771  7.161424e+06   -73.972558   \n",
       "std       0.372913     1.061662     0.034619  5.053893e+04     0.028900   \n",
       "min       0.000000     0.000000    40.656700  7.087701e+06   -74.045400   \n",
       "25%       1.000000     1.000000    40.727825  7.121546e+06   -73.991700   \n",
       "50%       1.000000     1.000000    40.751600  7.159454e+06   -73.977900   \n",
       "75%       1.000000     2.000000    40.773500  7.197719e+06   -73.954900   \n",
       "max       4.000000     8.000000    40.845500  7.731327e+06   -73.714200   \n",
       "\n",
       "             price  \n",
       "count  9086.000000  \n",
       "mean   3321.198767  \n",
       "std    1106.764221  \n",
       "min     950.000000  \n",
       "25%    2500.000000  \n",
       "50%    3100.000000  \n",
       "75%    3919.750000  \n",
       "max    6540.000000  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lat = df1['latitude']\n",
    "\n",
    "IQR = df_lat.quantile(0.75)-df_lat.quantile(0.25)\n",
    "upper = df_lat.quantile(0.75)+IQR*1.5\n",
    "lower = df_lat.quantile(0.25)-IQR*1.5\n",
    " \n",
    "df2 = df1[(df1['latitude']<upper) & (df1['latitude']>lower)]\n",
    "df2.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Longitude Attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>8906.000000</td>\n",
       "      <td>8906.000000</td>\n",
       "      <td>8906.000000</td>\n",
       "      <td>8.906000e+03</td>\n",
       "      <td>8906.000000</td>\n",
       "      <td>8906.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.140972</td>\n",
       "      <td>1.474736</td>\n",
       "      <td>40.751176</td>\n",
       "      <td>7.161509e+06</td>\n",
       "      <td>-73.975053</td>\n",
       "      <td>3347.780148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.372746</td>\n",
       "      <td>1.064818</td>\n",
       "      <td>0.034617</td>\n",
       "      <td>5.075830e+04</td>\n",
       "      <td>0.022844</td>\n",
       "      <td>1098.383624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.656700</td>\n",
       "      <td>7.087701e+06</td>\n",
       "      <td>-74.045400</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.728500</td>\n",
       "      <td>7.121543e+06</td>\n",
       "      <td>-73.992100</td>\n",
       "      <td>2525.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.752050</td>\n",
       "      <td>7.159691e+06</td>\n",
       "      <td>-73.978400</td>\n",
       "      <td>3150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.774000</td>\n",
       "      <td>7.197980e+06</td>\n",
       "      <td>-73.956300</td>\n",
       "      <td>3950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>40.845500</td>\n",
       "      <td>7.731327e+06</td>\n",
       "      <td>-73.899900</td>\n",
       "      <td>6540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms     bedrooms     latitude    listing_id    longitude  \\\n",
       "count  8906.000000  8906.000000  8906.000000  8.906000e+03  8906.000000   \n",
       "mean      1.140972     1.474736    40.751176  7.161509e+06   -73.975053   \n",
       "std       0.372746     1.064818     0.034617  5.075830e+04     0.022844   \n",
       "min       0.000000     0.000000    40.656700  7.087701e+06   -74.045400   \n",
       "25%       1.000000     1.000000    40.728500  7.121543e+06   -73.992100   \n",
       "50%       1.000000     1.000000    40.752050  7.159691e+06   -73.978400   \n",
       "75%       1.000000     2.000000    40.774000  7.197980e+06   -73.956300   \n",
       "max       4.000000     8.000000    40.845500  7.731327e+06   -73.899900   \n",
       "\n",
       "             price  \n",
       "count  8906.000000  \n",
       "mean   3347.780148  \n",
       "std    1098.383624  \n",
       "min     950.000000  \n",
       "25%    2525.000000  \n",
       "50%    3150.000000  \n",
       "75%    3950.000000  \n",
       "max    6540.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = df2['longitude']\n",
    " \n",
    "IQR = df_long.quantile(0.75)-df_long.quantile(0.25)\n",
    "upper = df_long.quantile(0.75)+IQR*1.5\n",
    "lower = df_long.quantile(0.25)-IQR*1.5 \n",
    "df3 = df2[(df2['longitude'] >lower) & (df2['longitude']<upper)]\n",
    "df3.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bedrooms Attribute  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>8627.000000</td>\n",
       "      <td>8627.000000</td>\n",
       "      <td>8627.000000</td>\n",
       "      <td>8.627000e+03</td>\n",
       "      <td>8627.000000</td>\n",
       "      <td>8627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.120552</td>\n",
       "      <td>1.389939</td>\n",
       "      <td>40.750966</td>\n",
       "      <td>7.161469e+06</td>\n",
       "      <td>-73.975264</td>\n",
       "      <td>3289.211661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.349161</td>\n",
       "      <td>0.967729</td>\n",
       "      <td>0.034350</td>\n",
       "      <td>5.096753e+04</td>\n",
       "      <td>0.022823</td>\n",
       "      <td>1051.207909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.656700</td>\n",
       "      <td>7.087719e+06</td>\n",
       "      <td>-74.045400</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.728500</td>\n",
       "      <td>7.121489e+06</td>\n",
       "      <td>-73.992200</td>\n",
       "      <td>2500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.751800</td>\n",
       "      <td>7.159435e+06</td>\n",
       "      <td>-73.978600</td>\n",
       "      <td>3100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.773600</td>\n",
       "      <td>7.197934e+06</td>\n",
       "      <td>-73.956300</td>\n",
       "      <td>3850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.845500</td>\n",
       "      <td>7.731327e+06</td>\n",
       "      <td>-73.899900</td>\n",
       "      <td>6540.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bathrooms     bedrooms     latitude    listing_id    longitude  \\\n",
       "count  8627.000000  8627.000000  8627.000000  8.627000e+03  8627.000000   \n",
       "mean      1.120552     1.389939    40.750966  7.161469e+06   -73.975264   \n",
       "std       0.349161     0.967729     0.034350  5.096753e+04     0.022823   \n",
       "min       0.000000     0.000000    40.656700  7.087719e+06   -74.045400   \n",
       "25%       1.000000     1.000000    40.728500  7.121489e+06   -73.992200   \n",
       "50%       1.000000     1.000000    40.751800  7.159435e+06   -73.978600   \n",
       "75%       1.000000     2.000000    40.773600  7.197934e+06   -73.956300   \n",
       "max       3.000000     3.000000    40.845500  7.731327e+06   -73.899900   \n",
       "\n",
       "             price  \n",
       "count  8627.000000  \n",
       "mean   3289.211661  \n",
       "std    1051.207909  \n",
       "min     950.000000  \n",
       "25%    2500.000000  \n",
       "50%    3100.000000  \n",
       "75%    3850.000000  \n",
       "max    6540.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bedrooms = df3['bedrooms']\n",
    " \n",
    "IQR = df_bedrooms.quantile(0.75)-df_bedrooms.quantile(0.25)\n",
    "upper = df_bedrooms.quantile(0.75)+IQR*1.5\n",
    "lower = max(df_bedrooms.quantile(0.25)-IQR*1.5, 0)\n",
    " \n",
    "df4 = df3[(df3['bedrooms'] >= lower) & (df3['bedrooms'] <= upper)]\n",
    "df4.describe()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Bathrooms Attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>7424.0</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7.424000e+03</td>\n",
       "      <td>7424.000000</td>\n",
       "      <td>7424.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.242592</td>\n",
       "      <td>40.751037</td>\n",
       "      <td>7.161486e+06</td>\n",
       "      <td>-73.975252</td>\n",
       "      <td>3080.026536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919507</td>\n",
       "      <td>0.034527</td>\n",
       "      <td>5.136457e+04</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>871.394296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.656700</td>\n",
       "      <td>7.087719e+06</td>\n",
       "      <td>-74.032100</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.728400</td>\n",
       "      <td>7.121154e+06</td>\n",
       "      <td>-73.992400</td>\n",
       "      <td>2475.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.751600</td>\n",
       "      <td>7.159556e+06</td>\n",
       "      <td>-73.978700</td>\n",
       "      <td>2950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.773500</td>\n",
       "      <td>7.198079e+06</td>\n",
       "      <td>-73.956200</td>\n",
       "      <td>3550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.845400</td>\n",
       "      <td>7.731327e+06</td>\n",
       "      <td>-73.899900</td>\n",
       "      <td>6500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bathrooms     bedrooms     latitude    listing_id    longitude  \\\n",
       "count     7424.0  7424.000000  7424.000000  7.424000e+03  7424.000000   \n",
       "mean         1.0     1.242592    40.751037  7.161486e+06   -73.975252   \n",
       "std          0.0     0.919507     0.034527  5.136457e+04     0.022902   \n",
       "min          1.0     0.000000    40.656700  7.087719e+06   -74.032100   \n",
       "25%          1.0     1.000000    40.728400  7.121154e+06   -73.992400   \n",
       "50%          1.0     1.000000    40.751600  7.159556e+06   -73.978700   \n",
       "75%          1.0     2.000000    40.773500  7.198079e+06   -73.956200   \n",
       "max          1.0     3.000000    40.845400  7.731327e+06   -73.899900   \n",
       "\n",
       "             price  \n",
       "count  7424.000000  \n",
       "mean   3080.026536  \n",
       "std     871.394296  \n",
       "min     950.000000  \n",
       "25%    2475.000000  \n",
       "50%    2950.000000  \n",
       "75%    3550.000000  \n",
       "max    6500.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bathrooms = df4['bathrooms']\n",
    " \n",
    "IQR = df_bathrooms.quantile(0.75)-df_bathrooms.quantile(0.25)\n",
    "\n",
    "upper = math.ceil(df_bathrooms.quantile(0.75)+IQR*1.5)\n",
    "lower = max(df_bathrooms.quantile(0.25)-IQR*1.5, 0)\n",
    "average = sum(df_bathrooms) / len(df_bathrooms)\n",
    "\n",
    "df5 = df4[(df4['bathrooms'] >= lower) & (df4['bathrooms'] <= upper)]\n",
    "df5.describe()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Features Attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>building_id</th>\n",
       "      <th>created</th>\n",
       "      <th>description</th>\n",
       "      <th>display_address</th>\n",
       "      <th>features</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>wheelchair ramp</th>\n",
       "      <th>wifi</th>\n",
       "      <th>wifi access</th>\n",
       "      <th>windows</th>\n",
       "      <th>windows galore</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>work laundry</th>\n",
       "      <th>work pre</th>\n",
       "      <th>yoga</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>04f5b303e487287cd749a5a3073a4d4e</td>\n",
       "      <td>2016-06-24 07:29:05</td>\n",
       "      <td>Astonishing colossal 1 bedroom in Prime Midtow...</td>\n",
       "      <td>West 48th Street</td>\n",
       "      <td>[Hardwood Floors]</td>\n",
       "      <td>40.7627</td>\n",
       "      <td>7210791</td>\n",
       "      <td>-73.9905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>cb51f30e806da9410ac968ef0cc25c9d</td>\n",
       "      <td>2016-06-29 06:37:37</td>\n",
       "      <td>A large, renovated true three bedroom apartmen...</td>\n",
       "      <td>East 95th Street</td>\n",
       "      <td>[Garden/Patio, Pre-War, Laundry in Building, L...</td>\n",
       "      <td>40.7839</td>\n",
       "      <td>7233657</td>\n",
       "      <td>-73.9488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>a3df5e1e3d4479eb07e112e569bbeb05</td>\n",
       "      <td>2016-06-08 02:59:36</td>\n",
       "      <td>Beautiful Renovated Really Large 1BR in the  G...</td>\n",
       "      <td>E 18 Street</td>\n",
       "      <td>[Doorman, Elevator, Dishwasher, Hardwood Floor...</td>\n",
       "      <td>40.7358</td>\n",
       "      <td>7124045</td>\n",
       "      <td>-73.9859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0a478756a98f68d50271c3eb46847372</td>\n",
       "      <td>2016-06-17 03:20:20</td>\n",
       "      <td>Gut renovated and beautifully sun drenched stu...</td>\n",
       "      <td>W 8 Street</td>\n",
       "      <td>[Cats Allowed, Dogs Allowed, Dishwasher, Hardw...</td>\n",
       "      <td>40.7336</td>\n",
       "      <td>7176171</td>\n",
       "      <td>-73.9991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>bb8658a3e432fb62a440615333376345</td>\n",
       "      <td>2016-06-18 03:19:03</td>\n",
       "      <td>Flexible move-in dates available for this flex...</td>\n",
       "      <td>Washington Street</td>\n",
       "      <td>[Roof Deck, Doorman, Elevator, Fitness Center,...</td>\n",
       "      <td>40.7080</td>\n",
       "      <td>7181004</td>\n",
       "      <td>-74.0149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>34b75f03d5877e3e023e49e807ff8076</td>\n",
       "      <td>2016-06-07 02:13:42</td>\n",
       "      <td>Very Large and Renovated 2 Bedroom Railroad ap...</td>\n",
       "      <td>31-57 42nd St</td>\n",
       "      <td>[Newly renovated, No pets]</td>\n",
       "      <td>40.7591</td>\n",
       "      <td>7117652</td>\n",
       "      <td>-73.9164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>eaea5041914df950dc56f7782a35e426</td>\n",
       "      <td>2016-06-21 05:07:34</td>\n",
       "      <td>Beautiful  1BR in the Upper East Side** If you...</td>\n",
       "      <td>E 65 Street</td>\n",
       "      <td>[Hardwood Floors]</td>\n",
       "      <td>40.7631</td>\n",
       "      <td>7191437</td>\n",
       "      <td>-73.9581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5fcf8f3a026126738344abdd4c61f2e2</td>\n",
       "      <td>2016-06-22 05:22:55</td>\n",
       "      <td>This Spacious Convertible 3 apartment with cit...</td>\n",
       "      <td>Rector Street</td>\n",
       "      <td>[Doorman, Elevator, Laundry in Unit, Dishwashe...</td>\n",
       "      <td>40.7083</td>\n",
       "      <td>7200182</td>\n",
       "      <td>-74.0149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-16 01:26:43</td>\n",
       "      <td>*Large one bedroom with a perfect Upper West S...</td>\n",
       "      <td>Broadway</td>\n",
       "      <td>[Swimming Pool, Doorman, Fitness Center, Dogs ...</td>\n",
       "      <td>40.7725</td>\n",
       "      <td>7166086</td>\n",
       "      <td>-73.9819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>80529abba2d1dabe6dffd7eeee281b70</td>\n",
       "      <td>2016-06-12 06:51:13</td>\n",
       "      <td>Modern and Convenient 2 Bedroom in Wil...</td>\n",
       "      <td>409 Broadway</td>\n",
       "      <td>[Elevator]</td>\n",
       "      <td>40.7069</td>\n",
       "      <td>7147370</td>\n",
       "      <td>-73.9532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 974 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms                       building_id              created  \\\n",
       "0        1.0         1  04f5b303e487287cd749a5a3073a4d4e  2016-06-24 07:29:05   \n",
       "1        1.0         3  cb51f30e806da9410ac968ef0cc25c9d  2016-06-29 06:37:37   \n",
       "2        1.0         1  a3df5e1e3d4479eb07e112e569bbeb05  2016-06-08 02:59:36   \n",
       "3        1.0         0  0a478756a98f68d50271c3eb46847372  2016-06-17 03:20:20   \n",
       "4        1.0         3  bb8658a3e432fb62a440615333376345  2016-06-18 03:19:03   \n",
       "5        1.0         3  34b75f03d5877e3e023e49e807ff8076  2016-06-07 02:13:42   \n",
       "6        1.0         1  eaea5041914df950dc56f7782a35e426  2016-06-21 05:07:34   \n",
       "7        1.0         3  5fcf8f3a026126738344abdd4c61f2e2  2016-06-22 05:22:55   \n",
       "8        1.0         1                                 0  2016-06-16 01:26:43   \n",
       "9        1.0         2  80529abba2d1dabe6dffd7eeee281b70  2016-06-12 06:51:13   \n",
       "\n",
       "                                         description    display_address  \\\n",
       "0  Astonishing colossal 1 bedroom in Prime Midtow...   West 48th Street   \n",
       "1  A large, renovated true three bedroom apartmen...   East 95th Street   \n",
       "2  Beautiful Renovated Really Large 1BR in the  G...        E 18 Street   \n",
       "3  Gut renovated and beautifully sun drenched stu...         W 8 Street   \n",
       "4  Flexible move-in dates available for this flex...  Washington Street   \n",
       "5  Very Large and Renovated 2 Bedroom Railroad ap...      31-57 42nd St   \n",
       "6  Beautiful  1BR in the Upper East Side** If you...        E 65 Street   \n",
       "7  This Spacious Convertible 3 apartment with cit...      Rector Street   \n",
       "8  *Large one bedroom with a perfect Upper West S...           Broadway   \n",
       "9          Modern and Convenient 2 Bedroom in Wil...       409 Broadway   \n",
       "\n",
       "                                            features  latitude  listing_id  \\\n",
       "0                                  [Hardwood Floors]   40.7627     7210791   \n",
       "1  [Garden/Patio, Pre-War, Laundry in Building, L...   40.7839     7233657   \n",
       "2  [Doorman, Elevator, Dishwasher, Hardwood Floor...   40.7358     7124045   \n",
       "3  [Cats Allowed, Dogs Allowed, Dishwasher, Hardw...   40.7336     7176171   \n",
       "4  [Roof Deck, Doorman, Elevator, Fitness Center,...   40.7080     7181004   \n",
       "5                         [Newly renovated, No pets]   40.7591     7117652   \n",
       "6                                  [Hardwood Floors]   40.7631     7191437   \n",
       "7  [Doorman, Elevator, Laundry in Unit, Dishwashe...   40.7083     7200182   \n",
       "8  [Swimming Pool, Doorman, Fitness Center, Dogs ...   40.7725     7166086   \n",
       "9                                         [Elevator]   40.7069     7147370   \n",
       "\n",
       "   longitude  ... wheelchair ramp wifi  wifi access windows windows galore  \\\n",
       "0   -73.9905  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "1   -73.9488  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "2   -73.9859  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "3   -73.9991  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "4   -74.0149  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "5   -73.9164  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "6   -73.9581  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "7   -74.0149  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "8   -73.9819  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "9   -73.9532  ...             0.0  0.0          0.0     0.0            0.0   \n",
       "\n",
       "   with  work  work laundry  work pre  yoga  \n",
       "0   0.0   0.0           0.0       0.0   0.0  \n",
       "1   0.0   0.0           0.0       0.0   0.0  \n",
       "2   0.0   0.0           0.0       0.0   0.0  \n",
       "3   0.0   0.0           0.0       0.0   0.0  \n",
       "4   0.0   0.0           0.0       0.0   0.0  \n",
       "5   0.0   0.0           0.0       0.0   0.0  \n",
       "6   0.0   0.0           0.0       0.0   0.0  \n",
       "7   0.0   0.0           0.0       0.0   0.0  \n",
       "8   0.0   0.0           0.0       0.0   0.0  \n",
       "9   0.0   0.0           0.0       0.0   0.0  \n",
       "\n",
       "[10 rows x 974 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.reset_index(drop=True, inplace=True)\n",
    "\n",
    "stopWords = stopwords.words('english')\n",
    "add_words = [\".\", \"..\", \"...\", \",\", \"/\", \"/lndry\", \":\", \"b\",\"’\", \"•\", \"this\",\n",
    "             \"l\", \"&\", \"*\", \"ss\", \"in\",\"**\", \"***\", \"!\",\"!!\",\"!!!\",\"!!!!\", \"w/\", \"(\", \")\", \n",
    "             \"'s\", \"$\", \"'\", \"..\", \"01\", \"01 16\",\"04\", \"05\", \"05 01\", \"06\", \"05 01 16\", \"0862\", \"in\"]\n",
    "stopWords.extend(add_words)\n",
    "\n",
    "\n",
    "features = df5['features']\n",
    "wordSetRow = []\n",
    "for words in features:\n",
    "    wordsForRows = \"\"\n",
    "    for word in words:\n",
    "        if word.lower() not in stopWords:\n",
    "            if(wordsForRows == \"\"):\n",
    "                wordsForRows = word.lower()\n",
    "            else:\n",
    "                wordsForRows = wordsForRows + \" \" + word.lower()\n",
    "                \n",
    "    wordSetRow.append(wordsForRows)\n",
    "\n",
    "cv=TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1,2))\n",
    "x_traincv = cv.fit_transform(wordSetRow)\n",
    "new_features = pd.DataFrame(\n",
    "    x_traincv.todense(),\n",
    "    columns=cv.get_feature_names(),\n",
    ")\n",
    "df6 = pd.concat([df5, new_features], axis=1, sort=False)\n",
    "df6.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification after outlier removal\n",
    "\n",
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After outlier removal:  0.6973063973063973\n"
     ]
    }
   ],
   "source": [
    "df7 = df6.drop(['features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "X=df7\n",
    "y = df6[\"interest_level\"]  \n",
    "\n",
    "X.shape, y.shape\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=0)\n",
    " \n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"After outlier removal: \", clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After outlier removal:  0.6973063973063973\n"
     ]
    }
   ],
   "source": [
    "df7 = df6.drop(['features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "X=df7\n",
    "y = df6[\"interest_level\"]  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=0)\n",
    " \n",
    "clf = SVC(gamma=10)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"After outlier removal: \", clf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "### 1. Logistic regression without modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df7 = df6.drop(['features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "X=df7[0:36406]\n",
    "y = df6[\"interest_level\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from the cross-validation:0.6741664365785744\n",
      "Model accuracy on the test dataset: 0.677737881508079\n",
      "F1 score: 0.5837856660402252\n",
      "Log loss: 0.8771373139223496\n"
     ]
    }
   ],
   "source": [
    "# Split labeled data into 60% training dataset and 40% test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, class_weight='balanced')\n",
    "\n",
    "# Performed 5-fold cross validation on the training dataset.\n",
    "clf = logreg.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Predict labels on the test data using the trained classifier.\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score by comparing predicted and actual labels.\n",
    "F1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# calculate log loss\n",
    "y_prob = logreg.predict_proba(X_test) \n",
    "logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Average accuracy from the cross-validation:\" + str(np.mean(scores)))\n",
    "print(\"Model accuracy on the test dataset: \" + str((logreg.score(X_test, y_test))))\n",
    "print(\"F1 score: \" + str(F1))\n",
    "print(\"Log loss: \" + str(logloss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Logistic regression after irrelevant feature removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from the cross-validation:0.6904081756326287\n",
      "Model accuracy on the test dataset: 0.6946529939571507\n",
      "F1 score: 0.5973492366875601\n",
      "Log loss: 0.7219180866397421\n"
     ]
    }
   ],
   "source": [
    "df7 = df6.drop([\"listing_id\",'bathrooms', 'bedrooms','features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "\n",
    "X=df7[0:36406]\n",
    "y = df6[\"interest_level\"]  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0)\n",
    " \n",
    "\n",
    "# Performed 5-fold cross validation on the training dataset.\n",
    "clf = logreg.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Predict labels on the test data using the trained classifier.\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score by comparing predicted and actual labels.\n",
    "F1 = f1_score(y_test, predictions, average='weighted')\n",
    " \n",
    "y_prob = logreg.predict_proba(X_test) \n",
    "logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "\n",
    "print(\"Average accuracy from the cross-validation:\" + str(np.mean(scores)))\n",
    "print(\"Model accuracy on the test dataset: \" + str((logreg.score(X_test, y_test))))\n",
    "print(\"F1 score: \" + str(F1))\n",
    "print(\"Log loss: \" + str(logloss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Logistic regression with data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from the cross-validation:0.6998939797095838\n",
      "Model accuracy on the test dataset: 0.703770197486535\n",
      "F1 score: 0.6151663159475064\n",
      "Log loss: 0.6977420408335882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df7 = df6.drop(['listing_id','features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "X=df7[0:36406]\n",
    "y = df6[\"interest_level\"]  \n",
    "# Split labeled data into 60% training dataset and 40% test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "normalizer = preprocessing.Normalizer().fit(X) \n",
    "normalizer.transform(X)\n",
    "\n",
    "# Performed 5-fold cross validation on the training dataset.\n",
    "clf = logreg.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Predict labels on the test data using the trained classifier.\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score by comparing predicted and actual labels.\n",
    "F1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# calculate log loss\n",
    "y_prob = logreg.predict_proba(X_test) \n",
    "logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Average accuracy from the cross-validation:\" + str(np.mean(scores)))\n",
    "print(\"Model accuracy on the test dataset: \" + str((logreg.score(X_test, y_test))))\n",
    "print(\"F1 score: \" + str(F1))\n",
    "print(\"Log loss: \" + str(logloss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic regression with regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from the cross-validation:0.7031263040419664\n",
      "Model accuracy on the test dataset: 0.7033213644524237\n",
      "F1 score: 0.6251883650930844\n",
      "Log loss: 0.6945645133254531\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df7 = df6.drop(['listing_id','features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "X=df7[0:36406]\n",
    "y = df6[\"interest_level\"]  \n",
    "# Split labeled data into 60% training dataset and 40% test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Set the inverse-regularization parameter C \n",
    "logreg = LogisticRegression(random_state=0, C=10**(7))\n",
    "\n",
    "normalizer = preprocessing.Normalizer().fit(X) \n",
    "normalizer.transform(X)\n",
    "\n",
    "# Performed 5-fold cross validation on the training dataset.\n",
    "clf = logreg.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Predict labels on the test data using the trained classifier.\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score by comparing predicted and actual labels.\n",
    "F1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# calculate log loss\n",
    "y_prob = logreg.predict_proba(X_test) \n",
    "logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Average accuracy from the cross-validation:\" + str(np.mean(scores)))\n",
    "print(\"Model accuracy on the test dataset: \" + str((logreg.score(X_test, y_test))))\n",
    "print(\"F1 score: \" + str(F1))\n",
    "print(\"Log loss: \" + str(logloss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = df6.drop(['bathrooms', 'bedrooms','features','description', 'building_id', 'manager_id',\n",
    "                'created', 'display_address', 'street_address', 'photos', 'interest_level'], axis=1)\n",
    "\n",
    "X=df7[0:36406]\n",
    "y = df6[\"interest_level\"]  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "svm = SVC(gamma=10)\n",
    "\n",
    "# Performe 5-fold cross validation on the training dataset, consisting of 4 training and 1 validation subsets.\n",
    "clf = svm.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Predict labels on the test data using the trained classifier.\n",
    "predictions = svm.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score by comparing predicted and actual labels.\n",
    "F1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "y_prob = logreg.predict_proba(X_test) \n",
    "logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "print(\"Average accuracy from the cross-validation:\" + str(np.mean(scores)))\n",
    "print(\"Model accuracy on the test dataset: \" + str((logreg.score(X_test, y_test))))\n",
    "print(\"F1 score: \" + str(F1))\n",
    "print(\"Log loss: \" + str(logloss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS (Distance from Manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>latitude</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "      <th>000</th>\n",
       "      <th>000 square</th>\n",
       "      <th>01</th>\n",
       "      <th>01 16</th>\n",
       "      <th>...</th>\n",
       "      <th>yard</th>\n",
       "      <th>yoga</th>\n",
       "      <th>yoga and</th>\n",
       "      <th>yoga room</th>\n",
       "      <th>yoga studio</th>\n",
       "      <th>york</th>\n",
       "      <th>york harbor</th>\n",
       "      <th>your</th>\n",
       "      <th>soho_long</th>\n",
       "      <th>soho_lati</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40.7108</td>\n",
       "      <td>7170325</td>\n",
       "      <td>-73.9539</td>\n",
       "      <td>2400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.7513</td>\n",
       "      <td>7092344</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>3800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.7575</td>\n",
       "      <td>7158677</td>\n",
       "      <td>-73.9625</td>\n",
       "      <td>3495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.0405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7439</td>\n",
       "      <td>7225292</td>\n",
       "      <td>-73.9743</td>\n",
       "      <td>2795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.0287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.7769</td>\n",
       "      <td>7114138</td>\n",
       "      <td>-73.9467</td>\n",
       "      <td>1945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.0563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2457 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  latitude  listing_id  longitude  price  000  \\\n",
       "0        1.0         1   40.7108     7170325   -73.9539   2400  0.0   \n",
       "1        1.0         2   40.7513     7092344   -73.9722   3800  0.0   \n",
       "2        1.0         2   40.7575     7158677   -73.9625   3495  0.0   \n",
       "3        1.0         0   40.7439     7225292   -73.9743   2795  0.0   \n",
       "4        1.0         0   40.7769     7114138   -73.9467   1945  0.0   \n",
       "\n",
       "   000 square   01  01 16  ...  yard  yoga  yoga and  yoga room  yoga studio  \\\n",
       "0         0.0  0.0    0.0  ...   0.0   0.0       0.0        0.0          0.0   \n",
       "1         0.0  0.0    0.0  ...   0.0   0.0       0.0        0.0          0.0   \n",
       "2         0.0  0.0    0.0  ...   0.0   0.0       0.0        0.0          0.0   \n",
       "3         0.0  0.0    0.0  ...   0.0   0.0       0.0        0.0          0.0   \n",
       "4         0.0  0.0    0.0  ...   0.0   0.0       0.0        0.0          0.0   \n",
       "\n",
       "   york  york harbor  your  soho_long  soho_lati  \n",
       "0   0.0          0.0   0.0     0.0125     0.0491  \n",
       "1   0.0          0.0   0.0     0.0280     0.0308  \n",
       "2   0.0          0.0   0.0     0.0342     0.0405  \n",
       "3   0.0          0.0   0.0     0.0206     0.0287  \n",
       "4   0.0          0.0   0.0     0.0536     0.0563  \n",
       "\n",
       "[5 rows x 2457 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Manhattan distance attributes and adding to the dataset\n",
    "df8 = df7\n",
    "soho_north = 40.7233\n",
    "soho_west = 74.0030\n",
    "df8['soho_long'] = abs(df7['latitude'] - soho_north)\n",
    "df8['soho_lati'] = abs(df7['longitude'] + soho_west)\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy from the cross-validation:0.6856012756120279\n",
      "Model accuracy on the test dataset: 0.6876945614356345\n",
      "F1 score: 0.5604376770946726\n",
      "Log loss: 0.7710650877181513\n"
     ]
    }
   ],
   "source": [
    "X=df8[0:36406] \n",
    "\n",
    "# Split labeled data into 60% training dataset and 40% test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0)\n",
    "\n",
    "# Performed 5-fold cross validation on the training dataset.\n",
    "clf = logreg.fit(X_train, y_train)\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "\n",
    "# Predict labels on the test data using the trained classifier.\n",
    "predictions = logreg.predict(X_test)\n",
    "\n",
    "# Calculate the F1 score by comparing predicted and actual labels.\n",
    "F1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# calculate log loss\n",
    "y_prob = logreg.predict_proba(X_test) \n",
    "logloss = log_loss(y_test, y_prob)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Average accuracy from the cross-validation:\" + str(np.mean(scores)))\n",
    "print(\"Model accuracy on the test dataset: \" + str((logreg.score(X_test, y_test))))\n",
    "print(\"F1 score: \" + str(F1))\n",
    "print(\"Log loss: \" + str(logloss))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
